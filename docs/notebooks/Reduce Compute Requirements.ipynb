{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f9b9f3a-6698-453c-a3be-40c567409e9c",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": "# Reduce Compute Requirements"
  },
  {
   "cell_type": "markdown",
   "id": "bdbb21e2ac2e0738",
   "metadata": {},
   "source": [
    "This tutorial shows which adjustments one can make to speed up SConnect computations while keeping the method output mostly the same.\n",
    "\n",
    "This tutorial is based on the original [pairOT tutorial](https://github.com/cellannotation/pairOT_package/blob/main/docs/notebooks/Tutorial.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fe34b7641af096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allow JAX to use all available GPU memory\n",
    "%env XLA_PYTHON_CLIENT_MEM_FRACTION=.99"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import anndata as ad\n",
    "import pandas as pd\n",
    "import pairot as pr\n",
    "import scanpy as sc\n",
    "\n",
    "from IPython.display import display, Image"
   ],
   "id": "aee7953ce84fd244"
  },
  {
   "cell_type": "markdown",
   "id": "d13b75a3-6e04-433e-8ada-c10d92b570b2",
   "metadata": {},
   "source": [
    "## 0. Required software and data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcb651e-7503-4f7a-8b82-7a532300bf7d",
   "metadata": {},
   "source": [
    "**Docker containers:**\n",
    "  * pairOT Docker container: https://hub.docker.com/repository/docker/felix0097/pairOT/general\n",
    "  * `docker pull felix0097/pairot:full_v1`\n",
    "\n",
    "**Datasets:**\n",
    "  * Van der Wijst (Query dataset): https://cellxgene.cziscience.com/collections/7d7cabfd-1d1f-40af-96b7-26a0825a306d\n",
    "  * Asian Immune Diversity Atlas (Reference dataset): https://celltype.info/project/336/dataset/591/label/71663\n",
    "\n",
    "**Required Hardware:**\n",
    "  * We used a Nvidia A40 GPU for this tutorial (48GB VRAM). Less VRAM is fine as well, one will need to reduce the `batch_size` parameter accordingly then.\n",
    "  * Moreover, for the `Data preparation` section, we recommend around 128GB of system memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fbb0b7-3b8a-46b1-aa64-f7fc44d2311f",
   "metadata": {},
   "source": [
    "## 1. Data preparation"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "query_dataset = \"7d7cabfd-1d1f-40af-96b7-26a0825a306d\"\n",
    "ref_dataset = \"ced320a1-29f3-47c1-a735-513c7084d508_CAP\"\n",
    "\n",
    "raw_data_path = Path(\"/vol/data/dataset-similarity/preprocessed\")\n",
    "preproc_data_path = Path(\"/vol/data/dataset-similarity/cache\")"
   ],
   "id": "8d1cac41c5cba902"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Preprocess datasets, this includes:\n",
    "# 1. Aligning/sort gene space\n",
    "# 2. Do differential expression testing\n",
    "# 3. Select highly variable genes\n",
    "adata_query, adata_ref = pr.pp.preprocess_adatas(\n",
    "    sc.read_h5ad(raw_data_path / f\"{query_dataset}.h5ad\"),\n",
    "    sc.read_h5ad(raw_data_path / f\"{ref_dataset}.h5ad\"),\n",
    "    n_top_genes=250,  # use less number of highly variable genes to speed up Spearman correlation computation\n",
    "    cell_type_column_adata1=\"cell_type_author\",\n",
    "    cell_type_column_adata2=\"cell_type_author\",\n",
    "    sample_column_adata1=\"sample_id\",\n",
    "    sample_column_adata2=\"sample_id\",\n",
    "    n_samples_auroc=10_000,  # only use 10,000 samples per cluster to speed up AUROC computation\n",
    "    n_samples_hvg_selection=100_000,  # only use 100,000 cells for HVG selection to reduce memory foot print\n",
    ")\n",
    "# Cache preprocessed data\n",
    "adata_query.write_h5ad(preproc_data_path / f\"{query_dataset}_small.h5ad\")\n",
    "adata_ref.write_h5ad(preproc_data_path / f\"{ref_dataset}_small.h5ad\")"
   ],
   "id": "abdb3eac33f671e2"
  },
  {
   "cell_type": "markdown",
   "id": "7e10fd92-31e7-4907-9cb9-6890c3b51dc0",
   "metadata": {},
   "source": [
    "**Changes to default settings:**\n",
    "* `n_top_genes`: Use 250 instead of 750 HVGs for computation of Spearman correlation. This reduces the GPU memory consumption and also speeds up the computation of the optimal transport model\n",
    "* `n_samples_auroc`: Sub-sample to max 10.000 samples to calculate AUROC scores for each gene. This will drastically, speed up the computation of AUROC scores.\n",
    "* `n_samples_hvg_selection`: Only use 100.000 genes per dataset to calculate highly variable genes. This will reduce memory consumption.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1f2968-1970-47a2-8fc2-74b0bb6f8c66",
   "metadata": {},
   "source": [
    "## 2. Initialize SConnect model"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "adata_query = ad.read_h5ad(preproc_data_path / f\"{query_dataset}_small.h5ad\")\n",
    "adata_ref = ad.read_h5ad(preproc_data_path / f\"{ref_dataset}_small.h5ad\")\n",
    "# Make sure that the genes have the same order in both dataset\n",
    "assert adata_query.var.index.equals(adata_ref.var.index)"
   ],
   "id": "795ddc9174559ce3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Subsample data before fitting OT model to speed up computation\n",
    "# To NOT loose rare cell-types, we only sub-sample cell-type clusters with more than n_samples samples\n",
    "# Those clusters get sub-samples to n_samples\n",
    "adata_query = adata_query[\n",
    "    pr.pp.downsample_indices(\n",
    "        adata_query.obs.cell_type_author.to_numpy(),\n",
    "        n_samples=10_000,\n",
    "    ),\n",
    "    :,\n",
    "]\n",
    "adata_ref = adata_ref[\n",
    "    pr.pp.downsample_indices(\n",
    "        adata_ref.obs.cell_type_author.to_numpy(),\n",
    "        n_samples=10_000,\n",
    "    ),\n",
    "    :,\n",
    "]\n",
    "print(f\"adata1: {adata_query.shape}\")\n",
    "print(f\"adata2: {adata_ref.shape}\")"
   ],
   "id": "47116bf9ff002a6"
  },
  {
   "cell_type": "markdown",
   "id": "e2df9e14-7c8f-407b-b902-dd66a10f92fe",
   "metadata": {},
   "source": [
    "**Changes to default settings:**\n",
    "* We subsample the data before fitting the optimal transport model.\n",
    "* The optimal transport model scales quadratically in the number of samples: `n_samples_query * n_samples_ref`\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "dataset_map = pr.tl.DatasetMap(adata_query, adata_ref)",
   "id": "2cb0022a6cc92738"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "dataset_map.init_geom(\n",
    "    batch_size=16192,\n",
    "    epsilon=0.05,\n",
    ")"
   ],
   "id": "af5d92dd09d4349b"
  },
  {
   "cell_type": "markdown",
   "id": "5a559d15-25cf-42f6-9581-dcb8ae742d4c",
   "metadata": {},
   "source": [
    "**Changes to default settings:**\n",
    "* `batch_size`\n",
    "  * We can now increase batch size (if the original data already fitted into memory)\n",
    "  * If the original data did not fit into memory, we now have a way higher chance that we're able to fit the model now\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e715f371-3870-4100-8412-30f6fef5e90f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x size: 0.170084628 GB\n",
      "y size: 0.273227556 GB\n"
     ]
    }
   ],
   "source": [
    "print(f\"x size: {dataset_map.geom.x.shape[0] * dataset_map.geom.x.shape[1] * 4 / 1000**3} GB\")\n",
    "print(f\"y size: {dataset_map.geom.y.shape[0] * dataset_map.geom.y.shape[1] * 4 / 1000**3} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fee69cb-b80c-4d1b-9366-e2088dbb5725",
   "metadata": {},
   "source": [
    "## 3. Fit SConnect model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d448771-a563-4640-b6a4-b9db22942ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_map.init_problem(tau_a=1.0, tau_b=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c002a5ac-396e-4ec9-a30d-0175d804c5f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|███████▍                                                                                                                                             | 10/200 [08:23<2:39:30, 50.37s/it, error: 5.184194e-04]\n"
     ]
    }
   ],
   "source": [
    "dataset_map.solve()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4408d8a-b7bd-4202-9005-a45a11580012",
   "metadata": {},
   "source": [
    "Fitting the SConnect model is significantly faster now. We could reduce the time it takes to fit the model from `~4.5 hours` to less than `10min`.\n",
    "\n",
    "To summarize how we achived this speedup:\n",
    "* Only using 250 highly variable genes instead of 750. Hence, speeding up the computation of the Spearman correlation. As has been shown by [Crow et al.](https://www.nature.com/articles/s41467-018-03282-0), this only has very minor effects on the calculated distances. But, significantly reduces computational costs. Moreover, this also reduces the GPU memory consumption.\n",
    "* Using less cells when fitting the optimal transport model. Again, this leaves the output mostly the same, while considerably reducing computational costs given that the OT model scales quadratically in the number of samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c069611b-104d-4e12-8dd8-4b94b64d1d5b",
   "metadata": {},
   "source": [
    "## 4. Results of SConnect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc241fe7-14f7-48cf-8c52-3e44eb087777",
   "metadata": {},
   "source": [
    "We can now compare the results of the downsampled SConnect model to the one that was fitted on the full dataset (see `SConnect_tutorial.ipynb`). As we can see below, the downsampling has little effect on the outputs of SConnect (cluster mapping + cluster distances), while signficantly reducing computational costs."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### OT mappings",
   "id": "3839b7fead1eb71a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "cluster_mapping = dataset_map.compute_mapping()",
   "id": "9b0b64ead7588f8f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "fig = pr.pl.mapping(cluster_mapping, sort_by_score=False)\n",
    "fig.update_layout(title=\"SConnect mapping using downsampled dataset\")\n",
    "# Interactive plotly plot isn't shown on GitHub\n",
    "fig"
   ],
   "id": "efb3accd8f28a473"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Show output as PNG image that it gets rendered on GitHub\n",
    "fig.write_image(\"cluster_mapping_downsampled.png\")\n",
    "display(Image(\"cluster_mapping_downsampled.png\"))"
   ],
   "id": "199cdbc059a374c0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "cluster_mapping_full = pd.read_parquet(\"mapping_mean.parquet\")\n",
    "\n",
    "fig = pr.pl.mapping(cluster_mapping_full, sort_by_score=False)\n",
    "fig.update_layout(title=\"SConnect mapping on using dataset (default settings)\")\n",
    "# Interactive plotly plot isn't shown on GitHub\n",
    "fig"
   ],
   "id": "98878decb2b91a6a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Show output as PNG image that it gets rendered on GitHub\n",
    "fig.write_image(\"cluster_mapping_full.png\")\n",
    "display(Image(\"cluster_mapping_full.png\"))"
   ],
   "id": "4f2ddf3d8e1f7abf"
  },
  {
   "cell_type": "markdown",
   "id": "49b92a53-d760-4c72-89fc-f564aef69a83",
   "metadata": {},
   "source": "### Cluster distance"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c12f82e6-f81c-4b27-a0a4-ba66ad1d0fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1050/1050 [04:35<00:00,  3.81it/s]\n"
     ]
    }
   ],
   "source": "cluster_distance = dataset_map.compute_distance()"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Sort cluster distances by mapping scores as well\n",
    "fig = pr.pl.distance(cluster_distance)\n",
    "fig.update_layout(title=\"SConnect distance using downsampled dataset\")\n",
    "# Interactive plotly plot isn't shown on GitHub\n",
    "fig"
   ],
   "id": "25ced97c79e88eaf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Show output as PNG image that it gets rendered on GitHub\n",
    "fig.write_image(\"cluster_distance_downsampled.png\")\n",
    "display(Image(\"cluster_distance_downsampled.png\"))"
   ],
   "id": "21134920c7266af7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "cluster_distance_full = pd.read_parquet(\"distance.parquet\")\n",
    "\n",
    "fig = pr.pl.distance(cluster_distance_full)\n",
    "fig.update_layout(title=\"SConnect distance using full dataset (default setting)\")\n",
    "# Interactive plotly plot isn't shown on GitHub\n",
    "fig"
   ],
   "id": "edcf0204a94d927c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Show output as PNG image that it gets rendered on GitHub\n",
    "fig.write_image(\"cluster_distance_full.png\")\n",
    "display(Image(\"cluster_distance_full.png\"))"
   ],
   "id": "a6b7e1501a08da3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddda60c-0192-4894-9f0e-1fd75e6adb43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
